# Array vs Linked List

## Array

가장 기본적인 자료구조인 Array 자료구조는, 논리적 저장 순서와 물리적 저장 순서가 일치한다. 따라서 index로 해당 원소에 접근할 수 있다. 그렇기 때문에 찾고자 하는 원소의 인덱스 값을 알고 있으면 O(1)에 해당 원소로 접근할 수 있다. 즉 random access가 가능하다는 장점이 있다.

하지만 삭제 또는 삽입의 과정에서는 해당 원소에 접근하여 작업을 완료한 뒤 O(1), 또 한 가지의 작업을 추가적으로 해줘야 하기 때문에 시간이 더 걸린다. 만약 배열의 원소 중 어느 원소를 삭제했다고 했을 때, 배열의 연속적인 특징이 깨지게 된다. 즉 빈 공간이 생기는 것이다. 따라서 삭제한 원소보다 큰 인덱스를 갖는 원소들을 shift해줘야 하는 비용이 발생하고 이 경우의 시간 복잡도는 O(n)가 된다. 그렇기 때문에 Array 자료구조에서 삭제 기능에 대한 time complexity의 worst case는 O(n)이 된다.

삽입의 경우도 마찬가지 이다.

## Linked List

이 부분에 대한 문제점을 해결하기 위한 자료구조가 linked list이다. 각각의 원소들은 자기 자신 다음에 어떤 원소인지만을 기억하고 있다. 따라서 이 부분만 다른 값으로 바꿔주면 삭제와 삽입을 O(1)만에 해결할 수 있는 것이다.

하지만 Linked List 역시 한 가지 문제가 있다. 원하는 위치에 삽입을 하고자 하면 원하는 위치를 Search 과정에 있어서 첫번째 원소부터 다 확인해봐야 한다는 것이다. Array와는 달리 논리적 저장 순서와 물리적 저장 순서가 일치하지 않기 때문이다. 이것은 일단 삽입하고 정렬하는 것과 마찬가지이다. 이 과정 때문에, 어떠한 원소를 삭제 또는 추가하고자 했을 때, 그 원소를 찾기 위해서 O(n)의 시간이 추가적으로 발생하게 된다.

결국 linked list 자료구조는 search에도 O(n)의 time complexity를 갖고, 삽입, 삭제에 대해서도 O(n)의 time complexity를 갖는다. 그렇다고 해서 아주 쓸모없는 자료구조는 아니기에 우리가 학습하는 것이다. 이 Linked List는 Tree 구조의 근간이 되는 자료구조이며, Tree에서 사용되었을 때 그 유용성이 드러난다.

# Stack and Queue

Stack : LIFO
Queue : FIFO

# Tree

트리는 스택이나 큐와 같은 선형 구조가 아닌 비선형 자료구조이다. 트리는 계층적 관계를 표현하는 자료구조이다. 이 트리라는 자료구조는 표현에 집중한다. 무엇인가를 저장하고 꺼내야 한다는 사고에서 벗어나 트리라는 자료구조를 바라보자.

## 이진 트리

루트 노드를 중심으로 두 개의 서브 트리로 나뉘어 진다. 또한 나뉘어진 두 서브 트리도 모두 이진트리이어야 한다. 재귀적인 정의라 맞는듯 하면서도 이해가 쉽지 않을 듯하다. 한 가지 덧붙이자면 공집합도 이진 트리로 포함시켜야 한다. 그래야 재귀적으로 조건을 확인해갔을 때, leaf node에 다다랐을 때, 정의가 만족되기 때문이다. 자연스럽게 노드가 하나 뿐인 것도 이진 트리 정의에 만족하게 된다.

트리에서는 각 층별로 숫자를 매겨서 이를 트리의 레벨이라고 한다. 레벨의 값은 0부터 시작하고 따라서 루트 노드의 레벨은 0이다. 그리고 트리의 최고 레벨을 가리켜 해당 트리의 높이라고 한다.

## binary heap

배열에 기반한 complete binary tree이다.

## Red Black Tree

BST를 기반으로 하는 트리 형식의 자료구조이다. 동일한 노드의 갯수일 때, depth를 최소화하여 시간 복잡도를 줄이는 것이 핵심 아이디어이다.

# Hash Table

## Hash Function

특별한 알고리즘이란 것을 통해 고유한 인덱스 값을 설정하는 것이 중요해보인다. 위에서 언급한 '특별한 알고리즘'을 hash method 또는 해시 함수라고 하고 이 메소드에 의해 반환된 데이터의 고유 숫자 값을 hashcode라고 한다. 저장되는 값들의 key 값을 hash function을 통해서 작은 범위의 값들로 바꿔준다.

하지만 어설픈 hash function을 통해서 key 값들을 결정한다면 동일한 값이 도출될 수가 있다. 이렇게 되면 동일한 key 값에 복수 개의 데이터가 하나의 테이블에 존재할 수 있게 되는 것인데 이를 collision이라고 한다.

### 그렇다면 좋은 hash function는 어떠한 조건들을 갖추고 있어야 하는가?

일반적으로 좋은 hash function는 키의 일부분을 참조하여 해쉬 값을 만들지 않고 키 전체를 참조하여 해쉬 값을 만들어 낸다. 하지만 좋은 해쉬 함수는 키가 어떤 특성을 가지고 있느냐에 따라 달라지게 된다.

hash function를 무조건 1:1로 만드는 것보다 collision을 최소화하는 방향으로 설계하고 발생하는 collision에 대비해 어떻게 대응할 것인가가 더 중요하다. 1:1 대응이 되도록 만드는 것이 거의 불가능하기도 하지만 그런 hash function를 만들어봤자 그건 array와 다를바 없고 메모리를 너무 차지하게 된다.

collision이 많아질 수록 search에 필요한 time complexity가 O(1)에서 O(n)에 가까워진다. 어설픈 hash function는 hash를 hash답게 사용하지 못하도록 한다. 좋은 hash function를 선택하는 것은 해시 테이블의 성능 향상에 필수적인 것이다.

따라서 hashing된 인덱스에 이미 다른 값이 들어 있다면 새 데이터를 저장할 다른 위치를 찾은 뒤에야 저장할 수 있는 것이다. 따라서 충돌 해결은 필수이며 그 방법들에 대해 알아보자.

## Resolve Conflict

기본적인 두 가지 방법부터 알아보자. 해시 충돌을 해결하기 위한 다양한 자료가 있지만, 다음 두 가지 방법을 응용한 방법들이기 때문이다.

1. Open Address 방식 (개방주소법)

해시 충돌이 발생하면, 다른 해시 버킷에 해당 자료를 삽입하는 방식이다. 버킷이란 바구니와 같은 개념으로 데이터를 저장하기 위한 공간이라고 생각하면 된다. 다른 해시 버킷이란 어떤 해시 버킷을 말하는 것인가?

공개 주소 방식이라고도 불리는 이 알고리즘은 collision이 발생하면 데이터를 저장할 장소를 찾아 해맨다. worst case의 경우 비어있는 버킷을 찾지 못하고 탐색을 시작한 위치까지 되돌아 올 수 있다. 이 과정에서도 여러 방법들이 존재하는데, 다음 세 가지에 대해 알아보자.

    1. linear probing : 순차적으로 탐색하며 비어있는 버킷을 찾을 때 까지 계속 진행된다.
    2. Quadratic probing : 2차 함수를 이용해 탐색할 위치를 찾는다.
    3. Double hashing probing : 하나의 해시 함수에서 충돌이 발생하면 2차 해쉬 함수를 이용해 새로운 주소를 할당한다. 위 두가지 방법에 비해 많은 연산량을 요구하게 된다.

2. Seperate Chaining 방식 (분리 연결법)

일반적으로 Open Addressing 은 seperate chaining보다 느리다. open addressing의 경우 해시 버킷을 채운 밀도가 높아질수록 worst case 발생 빈도가 더 높아지기 때문이다. 반면 seperate chaining 방식의 경우 해시 충돌이 잘 발생하지 않도록 보조 해시 함수를 통해 조정할 수 있다면 worst case에 가까워지는 빈도를 줄일 수 있다. java7에서는 seperate chaining 방식을 사용하여 HashMap을 구현하고 있다. Seperate Chaining 방식으로는 두 가지 구현 방식이 존재한다.

    - 연결 리스트를 사용하는 방식 : 각각의 버킷들을 연결리스트로 만ㄷ르어 collision이 발생하면 해당 bucket의 list에 추가하는 방식이다.

    - Tree를 사용하는 방식 : 기본적인 알고리즘은 seperate chaining방식과 동일하며 연결 리스트 대신 트리를 사용하는 방식이다.

### open address vs seperate chaining

일단 두 방식 모두 worst case에서 O(M)이다. 하지만 Open Address 방식은 연속된 공간에 데이터를 저장하기 때문에 seperate chaining에 비해 캐시 효율이 높다. 따라서 데이터의 개수가 충분히 적다면 open address 방식이 seperate chaining 보다 더 성능이 좋다. 한가지 차이점이 더 존재한다. seperate chaining 방식에 비해 open address 방식은 버킷을 계속해서 사용한다. 따라서 seperate chaining 방식은 테이블의 확장을 보다 늦출 수 있다.

## 해시 버킷 동적 확장

해시 버킷의 개수가 적다면 메모리 사용을 아낄 수 있지만 해시 충돌로 인해 성능 상 손실이 발생한다. 그래서 hashmap은 key-value 쌍 데이터 개수가 일정 개수 이상이 되면 해시 버킷의 개수를 두 배로 늘린다. 이렇게 늘리면 해시 충돌로 인한 성능 손실 문제를 어느 정도 해결할 수 있다. 또 애매모호한 '일정 개수 이상'이라는 표현이 등장했다. 해시 버킷 크기를 두 배로 확장하는 임계점은 현재 데이터 개수가 해시 버킷의 개수가 75%가 될 때이다. 0.75라는 숫자는 load factor라고 불린다.

# Graph

## 그래프를 구현하는 두 방법

- 인접 행렬 : 정방 행렬을 사용하는 방법
- 인접 리스트 : 연결 리스트를 사용하는 방법

## 그래프 탐핵

- DFS
- BFS

